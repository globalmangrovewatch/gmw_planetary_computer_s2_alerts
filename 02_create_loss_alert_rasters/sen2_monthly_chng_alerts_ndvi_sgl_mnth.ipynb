{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e433bd7-4cde-4386-a79a-99b0d2a3d024",
   "metadata": {},
   "source": [
    "# Single Month Analysis\n",
    "\n",
    "This notebook only processes a single month of data rather undertaking an analysis of a whole year. This will be more efficient when just running a single month (i.e., maintaining the alerts) but should not be used when processing multiple months. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0acd45d3-63a9-4aa5-a4c7-cc2ebcb0dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from dask_gateway import GatewayCluster\n",
    "#import dask.distributed\n",
    "import planetary_computer\n",
    "from pystac_client import Client\n",
    "import odc.stac\n",
    "import geopandas\n",
    "import numpy\n",
    "import rasterio\n",
    "import xarray\n",
    "import os\n",
    "import json\n",
    "import urllib\n",
    "import time\n",
    "import coiled\n",
    "from azure.storage.blob import BlobClient\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad40b5-b72e-4ea9-a082-6c2d6d9c609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sen2_vld_msk(scns_xa, bands, qa_pxl_msk=\"SCL\", out_no_data_val=0):\n",
    "    scns_lcl_xa = scns_xa.copy()\n",
    "    for band in bands:\n",
    "        scns_lcl_xa[band].values[\n",
    "            scns_lcl_xa[qa_pxl_msk].values == 0\n",
    "        ] = out_no_data_val  # No Data\n",
    "        scns_lcl_xa[band].values[\n",
    "            scns_lcl_xa[qa_pxl_msk].values == 1\n",
    "        ] = out_no_data_val  # Saturation\n",
    "        scns_lcl_xa[band].values[\n",
    "            scns_lcl_xa[qa_pxl_msk].values == 2\n",
    "        ] = out_no_data_val  # Cast Shadow\n",
    "        scns_lcl_xa[band].values[\n",
    "            scns_lcl_xa[qa_pxl_msk].values == 3\n",
    "        ] = out_no_data_val  # Cloud Shadows\n",
    "        scns_lcl_xa[band].values[\n",
    "            scns_lcl_xa[qa_pxl_msk].values == 8\n",
    "        ] = out_no_data_val  # Cloud Medium Probability\n",
    "        scns_lcl_xa[band].values[\n",
    "            scns_lcl_xa[qa_pxl_msk].values == 9\n",
    "        ] = out_no_data_val  # Cloud High Probability\n",
    "        scns_lcl_xa[band].values[\n",
    "            scns_lcl_xa[qa_pxl_msk].values == 10\n",
    "        ] = out_no_data_val  # Thin Cirrus\n",
    "    return scns_lcl_xa\n",
    "\n",
    "\n",
    "def apply_sen2_offset(sen2_scns_xa, offset=-1000):\n",
    "\n",
    "    # Define the date splitting whether the offset should be applied.\n",
    "    off_date = numpy.datetime64(\"2022-01-25\")\n",
    "    # Get Minimum date in timeseries\n",
    "    time_min = sen2_scns_xa.time.min().values\n",
    "    # Get Maximum date in timeseries\n",
    "    time_max = sen2_scns_xa.time.max().values\n",
    "\n",
    "    # Get the list of variables\n",
    "    bands = list(sen2_scns_xa.data_vars)\n",
    "    # List of all bands for which offset should be applied if present.\n",
    "    s2_img_bands = [\n",
    "        \"B01\",\n",
    "        \"B02\",\n",
    "        \"B03\",\n",
    "        \"B04\",\n",
    "        \"B05\",\n",
    "        \"B06\",\n",
    "        \"B07\",\n",
    "        \"B08\",\n",
    "        \"B8A\",\n",
    "        \"B09\",\n",
    "        \"B10\",\n",
    "        \"B11\",\n",
    "        \"B12\",\n",
    "    ]\n",
    "\n",
    "    if (time_min < off_date) and (time_max > off_date):\n",
    "        # Crosses the offset data and therefore part of the dataset needs offset applying\n",
    "        sen2_scns_xa_pre_off = sen2_scns_xa.sel(time=slice(time_min, off_date))\n",
    "        sen2_scns_xa_post_off = sen2_scns_xa.sel(time=slice(off_date, time_max))\n",
    "        for band in bands:\n",
    "            if band in s2_img_bands:\n",
    "                sen2_scns_xa_post_off[band] = sen2_scns_xa_post_off[band] + offset\n",
    "                sen2_scns_xa_post_off[band].where(sen2_scns_xa_post_off[band] < 0, 0)\n",
    "                sen2_scns_xa_post_off[band].where(\n",
    "                    sen2_scns_xa_post_off[band] > 10000, 0\n",
    "                )\n",
    "        sen2_scns_xa = xarray.concat(\n",
    "            [sen2_scns_xa_pre_off, sen2_scns_xa_post_off], dim=\"time\"\n",
    "        )\n",
    "    elif time_min > off_date:\n",
    "        # All scenes after offset date apply to all\n",
    "        for band in bands:\n",
    "            if band in s2_img_bands:\n",
    "                sen2_scns_xa[band] = sen2_scns_xa[band] + offset\n",
    "                sen2_scns_xa[band].where(sen2_scns_xa[band] < 0, 0)\n",
    "                sen2_scns_xa[band].where(sen2_scns_xa[band] > 10000, 0)\n",
    "    # else: time_max < off_date:\n",
    "    # Do nothing - no offset required\n",
    "    return sen2_scns_xa\n",
    "\n",
    "\n",
    "def get_img_metadata(img_file):\n",
    "    img_data_obj = rasterio.open(img_file)\n",
    "    img_bounds = img_data_obj.bounds\n",
    "    img_bbox = [img_bounds.left, img_bounds.bottom, img_bounds.right, img_bounds.top]\n",
    "    img_x_res, img_y_res  = img_data_obj.res\n",
    "    if img_y_res > 0:\n",
    "        img_y_res = img_y_res * (-1)\n",
    "    img_data_obj = None\n",
    "    return img_bbox, img_x_res, img_y_res\n",
    "\n",
    "\n",
    "def get_img_band_array(img_file, band=1):\n",
    "    img_data_obj = rasterio.open(img_file)\n",
    "    img_arr = img_data_obj.read(band)\n",
    "    img_data_obj = None\n",
    "    return img_arr\n",
    "\n",
    "\n",
    "def find_month_end_date(year, month):\n",
    "    import calendar\n",
    "    cal = calendar.Calendar()\n",
    "    month_days = cal.monthdayscalendar(year, month)\n",
    "    max_day_month = numpy.array(month_days).flatten().max()\n",
    "    return max_day_month\n",
    "\n",
    "\n",
    "def zero_pad_num_str(\n",
    "    num_val: float,\n",
    "    str_len: int = 3,\n",
    "    round_num: bool = False,\n",
    "    round_n_digts: int = 0,\n",
    "    integerise: bool = False,\n",
    "    absolute: bool = False,\n",
    "    gain: float = 1,\n",
    ") -> str:\n",
    "    if absolute:\n",
    "        num_val = abs(num_val)\n",
    "    if round_num:\n",
    "        num_val = round(num_val, round_n_digts)\n",
    "    if integerise:\n",
    "        num_val = int(num_val * gain)\n",
    "\n",
    "    num_str = \"{}\".format(num_val)\n",
    "    num_str = num_str.zfill(str_len)\n",
    "    return num_str\n",
    "\n",
    "\n",
    "def test_asset_urls(signed_items):\n",
    "    chkd_items = list()\n",
    "    for scn_item in tqdm(signed_items):\n",
    "        assets_present = True\n",
    "        for asset_name in scn_item.assets:\n",
    "            try:\n",
    "                if (\n",
    "                    urllib.request.urlopen(scn_item.assets[asset_name].href).getcode()\n",
    "                    != 200\n",
    "                ):\n",
    "                    assets_present = False\n",
    "                    break\n",
    "            except urllib.error.HTTPError:\n",
    "                assets_present = False\n",
    "                break\n",
    "            time.sleep(0.1)\n",
    "        if assets_present:\n",
    "            chkd_items.append(scn_item)\n",
    "    print(f\"Before: {len(signed_items)}\")\n",
    "    print(f\"After: {len(chkd_items)}\")\n",
    "    return chkd_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec33b661-aa47-463b-932c-3d26d62655a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_recent_alerts(tile, p_year, p_month, out_dir, sas_token_info):   \n",
    "    month_str = zero_pad_num_str(p_month, str_len = 2, round_num = False, round_n_digts = 0)\n",
    "    date_str = f\"{p_year}{month_str}\"\n",
    "    \n",
    "    alerts_img_file = f\"gmw_{tile}_{date_str}_chg_alerts.tif\"\n",
    "    alerts_img_file_url = os.path.join(sas_token_info[\"url\"], out_dir, alerts_img_file)\n",
    "    #print(alerts_img_file_url)\n",
    "    alerts_img_file_url_signed = f\"{alerts_img_file_url}?{sas_token_info['sas_token']}\"\n",
    "    alerts_img_exists =  BlobClient.from_blob_url(alerts_img_file_url_signed).exists()\n",
    "\n",
    "    meta_img_file = f\"gmw_{tile}_{date_str}_chg_alerts_meta.tif\"\n",
    "    meta_img_file_url = os.path.join(sas_token_info[\"url\"], out_dir, meta_img_file)\n",
    "    #print(meta_img_file_url)\n",
    "    meta_img_file_url_signed = f\"{meta_img_file_url}?{sas_token_info['sas_token']}\"\n",
    "    meta_img_exists =  BlobClient.from_blob_url(meta_img_file_url_signed).exists()\n",
    "    \n",
    "    if alerts_img_exists and meta_img_exists:\n",
    "        # Read the layers in.\n",
    "        score_arr = get_img_band_array(meta_img_file_url_signed, band=1)\n",
    "        date_year_arr = get_img_band_array(meta_img_file_url_signed, band=2)\n",
    "        date_month_arr = get_img_band_array(meta_img_file_url_signed, band=3)\n",
    "    else:\n",
    "        raise Exception(f\"Image layers are not available: {tile}\")\n",
    "    \n",
    "    return score_arr, date_year_arr, date_month_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4217b0f8-beee-43ce-a104-238457af5520",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = coiled.Cluster(\n",
    "    n_workers=4,\n",
    "    region=\"westeurope\",\n",
    "    worker_memory=\"8 GiB\",\n",
    "    container='petebunting/gmw-alerts-contain'\n",
    "    #spot_policy=\"spot\",\n",
    ")\n",
    "client = cluster.get_client()\n",
    "print(cluster.dashboard_link)\n",
    "odc.stac.configure_rio(cloud_defaults=True, client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddeadce-9f71-46d9-bb07-feb827f70edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster = GatewayCluster()  # Creates the Dask Scheduler. Might take a minute.\n",
    "#cluster.adapt(minimum=4, maximum=24)\n",
    "#print(cluster.dashboard_link)\n",
    "\n",
    "#client = dask.distributed.Client(cluster, timeout=5)\n",
    "#odc.stac.configure_rio(cloud_defaults=True, client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe53db3-3418-4933-8bef-c3940f65d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2015b4-69e3-44e4-9700-a66d4c2508be",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [\"B04\", \"B08\", \"SCL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf183224-b694-4176-ab71-a984bae0a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tiles to be processed.\n",
    "tiles_gdf = geopandas.read_file(\"../00_base_data/alert_region_tiles.geojson\")\n",
    "tiles = tiles_gdf[\"tile\"].values\n",
    "# use to indicate range of tiles for batch processing (e.g. 0:100 for the 1st 100 or 400: for tile 400 to the end)\n",
    "tiles = tiles[:]\n",
    "\n",
    "tiles = tiles.tolist()\n",
    "#tiles.remove(\"N29W114\")\n",
    "#tiles.remove(\"N16W098\")\n",
    "#tiles.remove(\"N28W112\")\n",
    "#tiles.remove(\"N16W093\")\n",
    "\n",
    "# Change to just run some test tiles...\n",
    "#tiles = [\"N29W114\",\"N16W098\"]\n",
    "\n",
    "n_tiles = len(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ef6b6-6188-400a-93ae-e6a3f95b805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# significantly slows processing, only use when running tiles that produce e.g. http 404 errors, change to True for running separate tiles\n",
    "check_s2_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75966a5-0572-428d-9155-887f961794e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_info_file = \"/data/azure_info.json\"\n",
    "with open(sas_info_file) as f:\n",
    "    sas_token_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d2875-2aa3-4d05-ad84-a4a382a33077",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_path = \"monthly_change_imgs_tmp\"\n",
    "if not os.path.exists(tmp_path):\n",
    "    os.mkdir(tmp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b83e4b-77b8-4d60-8cd8-0ea8435a81d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img_dir = \"monthly_change_imgs\"\n",
    "gmw_base_dir = \"gmw_2018_revised\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b94122-3125-4502-a89f-21aa923a4808",
   "metadata": {},
   "source": [
    "## Update the month and year to be processed here:\n",
    "\n",
    "This is a litle tricky with the change in year and maybe could be tidied up but some examples:\n",
    "\n",
    "### Process Dec 2022:\n",
    "```\n",
    "c_year = 2022\n",
    "c_month = 12\n",
    "\n",
    "p_year = 2022\n",
    "p_month = 11\n",
    "```\n",
    "\n",
    "### Process Jan 2023:\n",
    "```\n",
    "c_year = 2023\n",
    "c_month = 1\n",
    "\n",
    "p_year = 2022\n",
    "p_month = 12\n",
    "```\n",
    "\n",
    "### Process Feb 2023\n",
    "```\n",
    "c_year = 2023\n",
    "c_month = 2\n",
    "\n",
    "p_year = 2023\n",
    "p_month = 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1c75c6-213e-49c6-82ec-059c94cb8f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The year and month to be processed - meta-data needs to be available for \n",
    "# the previous month (will be checked) and only the month of interest will \n",
    "# be processed.\n",
    "c_year = 2024\n",
    "c_month = 6\n",
    "# The previous month/year to the one to be processed to check that the data is available.\n",
    "p_year = 2024\n",
    "p_month = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb056727-9f07-4718-adde-6cc09d6bc313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S05W081: (1 of 535)\n",
      "\t2024-06-01/2024-06-30: N Items = 33\n",
      "\t2023-06-01/2023-06-30: N Items = 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 119.34 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 23.97 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCompleted: 2024 - 06\n",
      "N01W081: (2 of 535)\n",
      "\t2024-06-01/2024-06-30: N Items = 8\n",
      "\t2023-06-01/2023-06-30: N Items = 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 119.34 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 23.97 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCompleted: 2024 - 06\n",
      "N02W080: (3 of 535)\n",
      "\t2024-06-01/2024-06-30: N Items = 7\n",
      "\t2023-06-01/2023-06-30: N Items = 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 119.34 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 23.97 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCompleted: 2024 - 06\n",
      "S03W081: (4 of 535)\n",
      "\t2024-06-01/2024-06-30: N Items = 27\n",
      "\t2023-06-01/2023-06-30: N Items = 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 119.34 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 23.97 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCompleted: 2024 - 06\n",
      "N02W079: (5 of 535)\n",
      "\t2024-06-01/2024-06-30: N Items = 2\n",
      "\t2023-06-01/2023-06-30: N Items = 0\n",
      "\tCompleted: 2024 - 06\n",
      "S03W080: (6 of 535)\n",
      "\t2024-06-01/2024-06-30: N Items = 5\n",
      "\t2023-06-01/2023-06-30: N Items = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 119.34 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 23.97 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCompleted: 2024 - 06\n",
      "N01W080: (7 of 535)\n",
      "\t2024-06-01/2024-06-30: N Items = 4\n",
      "\t2023-06-01/2023-06-30: N Items = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 119.34 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 23.97 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCompleted: 2024 - 06\n",
      "S02W080: (8 of 535)\n",
      "\t2024-06-01/2024-06-30: N Items = 2\n",
      "\t2023-06-01/2023-06-30: N Items = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 119.34 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 23.97 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCompleted: 2024 - 06\n",
      "S04W082: (9 of 535)\n",
      "\t2024-06-01/2024-06-30: N Items = 20\n",
      "\t2023-06-01/2023-06-30: N Items = 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 119.34 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 23.97 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCompleted: 2024 - 06\n",
      "N00W081: (10 of 535)\n",
      "\t2024-06-01/2024-06-30: N Items = 8\n",
      "\t2023-06-01/2023-06-30: N Items = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 119.34 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 23.97 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCompleted: 2024 - 06\n",
      "S02W081: (11 of 535)\n",
      "\t2024-06-01/2024-06-30: N Items = 14\n",
      "\t2023-06-01/2023-06-30: N Items = 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 119.34 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 23.97 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCompleted: 2024 - 06\n",
      "N22W091: (12 of 535)\n",
      "\t2024-06-01/2024-06-30: N Items = 20\n",
      "\t2023-06-01/2023-06-30: N Items = 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 119.34 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 23.97 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCompleted: 2024 - 06\n",
      "N19W104: (13 of 535)\n",
      "\t2024-06-01/2024-06-30: N Items = 53\n",
      "\t2023-06-01/2023-06-30: N Items = 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 119.34 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 23.97 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCompleted: 2024 - 06\n",
      "N19W089: (14 of 535)\n",
      "\t2024-06-01/2024-06-30: N Items = 11\n",
      "\t2023-06-01/2023-06-30: N Items = 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 119.34 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 23.97 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCompleted: 2024 - 06\n",
      "N17W095: (15 of 535)\n",
      "\t2024-06-01/2024-06-30: N Items = 7\n",
      "\t2023-06-01/2023-06-30: N Items = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 119.34 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/distributed/client.py:3164: UserWarning: Sending large graph of size 23.97 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n_tile = 0\n",
    "for tile in tiles:\n",
    "    print(f\"{tile}: ({n_tile+1} of {n_tiles})\")\n",
    "    \n",
    "    month_str = zero_pad_num_str(c_month, str_len=2, round_num = False, round_n_digts = 0)\n",
    "    month_end_day = find_month_end_date(c_year, c_month)\n",
    "    month_end_day_str = zero_pad_num_str(month_end_day, str_len=2, round_num = False, round_n_digts = 0)\n",
    "    month_idx = c_month - 1\n",
    "    date_str = f\"{c_year}{month_str}\"\n",
    "    \n",
    "    # Path of the revised GMW 2018 extent image.\n",
    "    gmw_tile_img_file = f\"gmw_{tile}_2018_alerts_ext.tif\"\n",
    "    gmw_tile_img_url = os.path.join(sas_token_info[\"url\"], gmw_base_dir, gmw_tile_img_file)\n",
    "    gmw_tile_img_url_signed = f\"{gmw_tile_img_url}?{sas_token_info['sas_token']}\"\n",
    "        \n",
    "    # If the GMW 2018 tile does not exist then skip tile and go to the next one.\n",
    "    if not BlobClient.from_blob_url(gmw_tile_img_url_signed).exists():\n",
    "        print(\"\\tNo GMW Extent Tile Available...\")\n",
    "        n_tile += 1\n",
    "        continue\n",
    "        \n",
    "    # Output file names for the change alerts and associated metadata (i.e., score and date of first change observation).\n",
    "    out_meta_img_file = f\"gmw_{tile}_{date_str}_chg_alerts_meta.tif\"\n",
    "    out_alerts_img_file = f\"gmw_{tile}_{date_str}_chg_alerts.tif\"\n",
    "    \n",
    "    out_meta_img_file_url = os.path.join(sas_token_info[\"url\"], out_img_dir, out_meta_img_file)\n",
    "    out_meta_img_file_url_signed = f\"{out_meta_img_file_url}?{sas_token_info['sas_token']}\"\n",
    "    out_meta_img_exists =  BlobClient.from_blob_url(out_meta_img_file_url_signed).exists()\n",
    "    \n",
    "    out_alerts_img_file_url = os.path.join(sas_token_info[\"url\"], out_img_dir, out_alerts_img_file)\n",
    "    out_alerts_img_file_url_signed = f\"{out_alerts_img_file_url}?{sas_token_info['sas_token']}\"\n",
    "    out_alerts_img_exists =  BlobClient.from_blob_url(out_alerts_img_file_url_signed).exists()\n",
    "    \n",
    "    if out_meta_img_exists and out_alerts_img_exists:\n",
    "        print(\"\\tOutput images already exist...\")\n",
    "        n_tile += 1\n",
    "        continue\n",
    "    \n",
    "    # Get image tile meta-data\n",
    "    bbox, img_x_res, img_y_res = get_img_metadata(gmw_tile_img_url_signed)\n",
    "    # Get GMW Mask as array\n",
    "    gmw_ext_msk = get_img_band_array(gmw_tile_img_url_signed, band=2)\n",
    "    \n",
    "    # Check there are mangrove pixels within the scene (mangroves == 1)\n",
    "    if numpy.max(gmw_ext_msk) == 0:\n",
    "        print(\"\\tNo Mangrove Pixels in Mask...\")\n",
    "        del gmw_ext_msk\n",
    "        n_tile += 1\n",
    "        continue\n",
    "\n",
    "    # Get the image shape (i.e., number of pixels)\n",
    "    img_shp = gmw_ext_msk.shape\n",
    "\n",
    "    # Define the output image spatial transformation.\n",
    "    out_img_transform = rasterio.transform.Affine(img_x_res, 0.0, bbox[0], 0.0, img_y_res, bbox[3])\n",
    "    \n",
    "    # Load the meta data files from the previous month.\n",
    "    score_arr, date_year_arr, date_month_arr = find_recent_alerts(tile, p_year, p_month, out_img_dir, sas_token_info)\n",
    "    \n",
    "    # Create an empty array for the binary mask for the monthly alerts\n",
    "    month_alerts_arr = numpy.zeros_like(score_arr, dtype=numpy.uint8)\n",
    "    \n",
    "    ####################################################################\n",
    "    # Date range of the ROI (Beginning of Jan to end of Dec)\n",
    "    chng_time_range = f\"{c_year}-{month_str}-01/{c_year}-{month_str}-{month_end_day_str}\"\n",
    "    # Find the scenes for the year of interest.\n",
    "    chng_search = catalog.search(collections=[\"sentinel-2-l2a\"], bbox=bbox, datetime=chng_time_range, query={\"eo:cloud_cover\": {\"lt\": 50}})\n",
    "    chng_items = chng_search.item_collection()\n",
    "    n_chng_items = len(chng_items)\n",
    "    print(f\"\\t{chng_time_range}: N Items = {n_chng_items}\")\n",
    "    ####################################################################\n",
    "\n",
    "    ####################################################################\n",
    "    # Read the scenes into dask array structure and make persistant in memory\n",
    "    signed_chng_items = [planetary_computer.sign(item) for item in chng_items]\n",
    "    if check_s2_data:\n",
    "        signed_chng_items = test_asset_urls(signed_chng_items)\n",
    "    \n",
    "    if len(signed_chng_items) > 0:\n",
    "        sen2_chng_scn_xa = odc.stac.stac_load(\n",
    "            signed_chng_items,\n",
    "            bands=bands,\n",
    "            groupby=\"solar_day\",\n",
    "            chunks={\"time\":12, \"latitude\": 1024, \"longitude\": 1024},\n",
    "            bbox=bbox,\n",
    "            crs=\"EPSG:4326\",\n",
    "            resolution=img_x_res\n",
    "        )\n",
    "\n",
    "        # Comment out for larger datasets which don't fit into memory.\n",
    "        sen2_chng_scn_xa = sen2_chng_scn_xa.persist()\n",
    "\n",
    "        # Apply Offset\n",
    "        sen2_chng_scn_xa = apply_sen2_offset(sen2_chng_scn_xa)\n",
    "\n",
    "        # Apply cloud mask to all scenes\n",
    "        sen2_chng_scn_xa = sen2_chng_scn_xa.map_blocks(apply_sen2_vld_msk, kwargs={\"bands\":bands})\n",
    "        ####################################################################\n",
    "\n",
    "        ####################################################################\n",
    "        # 'Clean' up the Red and NIR bands to remove any values less than zero.\"\n",
    "        sen2_chng_scn_xa['B04'] = sen2_chng_scn_xa.B04.where(sen2_chng_scn_xa.B04>0)\n",
    "        sen2_chng_scn_xa['B08'] = sen2_chng_scn_xa.B08.where(sen2_chng_scn_xa.B08>0)\n",
    "\n",
    "        # Valid pixel mask\n",
    "        sen2_chng_vld_xa = sen2_chng_scn_xa.B04>0\n",
    "\n",
    "        # Calculate the NDVI\n",
    "        ndvi_chng_scn_xa = ((sen2_chng_scn_xa.B08-sen2_chng_scn_xa.B04)/(sen2_chng_scn_xa.B08+sen2_chng_scn_xa.B04))\n",
    "        ####################################################################\n",
    "\n",
    "\n",
    "        ####################################################################\n",
    "        # Date range of the year before ROI for checking changes have changed over the last 12 months.\n",
    "        ref_time_range = f\"{c_year-1}-{month_str}-01/{c_year-1}-{month_str}-{month_end_day_str}\"\n",
    "        # Search for reference scenes from year earlier than ROI.\n",
    "        ref_search = catalog.search(collections=[\"sentinel-2-l2a\"], bbox=bbox, datetime=ref_time_range, query={\"eo:cloud_cover\": {\"lt\": 50}})\n",
    "        ref_items = ref_search.item_collection()\n",
    "        n_ref_items = len(ref_items)\n",
    "        print(f\"\\t{ref_time_range}: N Items = {n_ref_items}\")\n",
    "        ####################################################################\n",
    "\n",
    "        ####################################################################\n",
    "        # Read the scenes into dask array structure and make persistant in memory\n",
    "        signed_ref_items = [planetary_computer.sign(item) for item in ref_items]\n",
    "        if check_s2_data:\n",
    "            signed_ref_items = test_asset_urls(signed_ref_items)\n",
    "        \n",
    "        if len(signed_ref_items) > 0:\n",
    "            sen2_ref_scn_xa = odc.stac.stac_load(\n",
    "                signed_ref_items,\n",
    "                bands=bands,\n",
    "                groupby=\"solar_day\",\n",
    "                chunks={\"time\":12, \"latitude\": 1024, \"longitude\": 1024},\n",
    "                bbox=bbox,\n",
    "                crs=\"EPSG:4326\",\n",
    "                resolution=img_x_res\n",
    "            )\n",
    "\n",
    "            # Comment out for larger datasets which don't fit into memory.\n",
    "            sen2_ref_scn_xa = sen2_ref_scn_xa.persist()\n",
    "\n",
    "            # Apply Offset\n",
    "            sen2_ref_scn_xa = apply_sen2_offset(sen2_ref_scn_xa)\n",
    "\n",
    "            # Apply cloud mask to all scenes\n",
    "            sen2_ref_scn_xa = sen2_ref_scn_xa.map_blocks(apply_sen2_vld_msk, kwargs={\"bands\":bands})\n",
    "            ####################################################################\n",
    "\n",
    "            ####################################################################\n",
    "            # 'Clean' up the Red and NIR bands to remove any values less than zero.\"\n",
    "            sen2_ref_scn_xa['B04'] = sen2_ref_scn_xa.B04.where(sen2_ref_scn_xa.B04>0)\n",
    "            sen2_ref_scn_xa['B08'] = sen2_ref_scn_xa.B08.where(sen2_ref_scn_xa.B08>0)\n",
    "\n",
    "            # Calculate the NDVI\n",
    "            ndvi_ref_scn_xa = ((sen2_ref_scn_xa.B08-sen2_ref_scn_xa.B04)/(sen2_ref_scn_xa.B08+sen2_ref_scn_xa.B04))\n",
    "\n",
    "            # Create monthly summaries\n",
    "            monthly_ref_ndvi_xa = ndvi_ref_scn_xa.median(dim=\"time\", skipna=True).compute()\n",
    "            ####################################################################\n",
    "\n",
    "            # Find the pixels of change for the month on a per-scene basis (i.e., NDVI < 0.25 and then difference in NDVI from a year earlier is > 0.15)\n",
    "            monthly_chng_pxls_xa = numpy.logical_and((ndvi_chng_scn_xa < 0.25), numpy.abs(ndvi_chng_scn_xa - monthly_ref_ndvi_xa) > 0.15)\n",
    "\n",
    "            # Get the valid masks for the current month\n",
    "            monthly_vld_pxls_scn_xa = sen2_chng_vld_xa\n",
    "\n",
    "            # Mask the GMW changes and valid masks to the GMW mask.\n",
    "            gmw_monthly_chng_pxls_xa = monthly_chng_pxls_xa.where(gmw_ext_msk == 1)\n",
    "            gmw_monthly_vld_pxls_scn_xa = monthly_vld_pxls_scn_xa.where(gmw_ext_msk == 1)\n",
    "\n",
    "            # Sum the number of changes observed in the scenes\n",
    "            gmw_monthly_chng_pxls_count_xa = gmw_monthly_chng_pxls_xa.sum(dim=\"time\", skipna=True)\n",
    "            # Sum the number of observations.\n",
    "            gmw_monthly_vld_pxls_count_xa = gmw_monthly_vld_pxls_scn_xa.sum(dim=\"time\", skipna=True)\n",
    "\n",
    "            # Run the compute in dask - before this no analysis actually happens it is just building the analysis graph\n",
    "            #dask.compute(gmw_monthly_chng_pxls_count_xa, gmw_monthly_vld_pxls_count_xa)\n",
    "\n",
    "            ####################################################################\n",
    "            # Update the score data values (Add 1 for a change and -1 for no change).\n",
    "            lcl_score_arr = score_arr + (gmw_monthly_chng_pxls_count_xa.values) - (gmw_monthly_vld_pxls_count_xa.values - gmw_monthly_chng_pxls_count_xa.values)\n",
    "            # Any pixels with a score of 5 before the analysis set back to 5 - they have already been identified as a change.\n",
    "            lcl_score_arr[score_arr == 5] = 5\n",
    "\n",
    "            # Update the date layers so that any pixels which have gone back to a score of 0 are reset.\n",
    "            date_year_arr[lcl_score_arr < 1] = 0\n",
    "            date_month_arr[lcl_score_arr < 1] = 0\n",
    "\n",
    "            # For pixels with a score > 0 without a date define, define the date as this is the first observation.\n",
    "            date_year_arr[(lcl_score_arr > 0) & (date_year_arr == 0)] = c_year\n",
    "            date_month_arr[(lcl_score_arr > 0) & (date_month_arr == 0)] = c_month\n",
    "\n",
    "            # Identify new confirmed alerts (i.e., the score has now reach 5).\n",
    "            month_alerts_arr[numpy.logical_and(score_arr<5, lcl_score_arr>4)] = 1\n",
    "\n",
    "            # Cap the score layer at 5 and don't allow scores lower than 0.\n",
    "            lcl_score_arr[lcl_score_arr>5] = 5\n",
    "            lcl_score_arr[lcl_score_arr<1] = 0\n",
    "\n",
    "            # Copy the local score image to replace the score image\n",
    "            score_arr = numpy.copy(lcl_score_arr)\n",
    "            ####################################################################\n",
    "\n",
    "            # Delete Monthly Objects.\n",
    "            del monthly_chng_pxls_xa\n",
    "            del monthly_vld_pxls_scn_xa\n",
    "            del gmw_monthly_chng_pxls_xa\n",
    "            del gmw_monthly_vld_pxls_scn_xa\n",
    "            del gmw_monthly_chng_pxls_count_xa\n",
    "            del gmw_monthly_vld_pxls_count_xa\n",
    "            del lcl_score_arr\n",
    "            \n",
    "            # Delete annual objects\n",
    "            del sen2_ref_scn_xa\n",
    "            del ndvi_ref_scn_xa\n",
    "            del monthly_ref_ndvi_xa\n",
    "            \n",
    "        del sen2_chng_scn_xa\n",
    "        del sen2_chng_vld_xa\n",
    "        del ndvi_chng_scn_xa\n",
    "            \n",
    "    ####################################################################\n",
    "    out_meta_img_file_tmp = os.path.join(tmp_path, out_meta_img_file)\n",
    "    out_alerts_img_file_tmp = os.path.join(tmp_path, out_alerts_img_file)\n",
    "\n",
    "    # Create the output image file for the metadata\n",
    "    with rasterio.open(out_meta_img_file_tmp,\n",
    "                                    'w',\n",
    "                                    driver='COG',\n",
    "                                    height=img_shp[0],\n",
    "                                    width=img_shp[1],\n",
    "                                    count=3,\n",
    "                                    dtype=numpy.uint16,\n",
    "                                    crs='epsg:4326',\n",
    "                                    transform=out_img_transform,\n",
    "                                ) as out_img_dataset:\n",
    "\n",
    "        # Write output array to the image file\n",
    "        out_img_dataset.write(score_arr, 1)\n",
    "        # Name the image band.\n",
    "        out_img_dataset.set_band_description(1, \"Alerts_Score\")\n",
    "\n",
    "        # Write output array to the image file\n",
    "        out_img_dataset.write(date_year_arr, 2)\n",
    "        # Name the image band.\n",
    "        out_img_dataset.set_band_description(2, \"Alert_Date_Year\")\n",
    "\n",
    "        # Write output array to the image file\n",
    "        out_img_dataset.write(date_month_arr, 3)\n",
    "        # Name the image band.\n",
    "        out_img_dataset.set_band_description(3, \"Alert_Date_Month\")\n",
    "    ####################################################################\n",
    "\n",
    "\n",
    "    ####################################################################\n",
    "    # Create the output image file for the newly identified alerts.\n",
    "    with rasterio.open(out_alerts_img_file_tmp,\n",
    "                                    'w',\n",
    "                                    driver='COG',\n",
    "                                    height=img_shp[0],\n",
    "                                    width=img_shp[1],\n",
    "                                    count=1,\n",
    "                                    dtype=numpy.uint8,\n",
    "                                    crs='epsg:4326',\n",
    "                                    transform=out_img_transform,\n",
    "                                ) as out_img_dataset:\n",
    "\n",
    "        # Write output array to the image file\n",
    "        out_img_dataset.write(month_alerts_arr, 1)\n",
    "        # Name the image band.\n",
    "        out_img_dataset.set_band_description(1, \"Alerts\")\n",
    "    ####################################################################\n",
    "    if os.path.exists(out_meta_img_file_tmp):\n",
    "        blob_client = BlobClient.from_blob_url(out_meta_img_file_url_signed)\n",
    "        with open(out_meta_img_file_tmp, 'rb') as data:\n",
    "            blob_client.upload_blob(data, overwrite=True)\n",
    "        blob_client = None\n",
    "        rasterio.shutil.delete(out_meta_img_file_tmp, driver=\"COG\")\n",
    "\n",
    "    if os.path.exists(out_alerts_img_file_tmp):\n",
    "        blob_client = BlobClient.from_blob_url(out_alerts_img_file_url_signed)\n",
    "        with open(out_alerts_img_file_tmp, 'rb') as data:\n",
    "            blob_client.upload_blob(data, overwrite=True)\n",
    "        blob_client = None\n",
    "        rasterio.shutil.delete(out_alerts_img_file_tmp, driver=\"COG\")\n",
    "    print(f\"\\tCompleted: {c_year} - {month_str}\")\n",
    "    \n",
    "    # Delete tile based arrays\n",
    "    del month_alerts_arr\n",
    "    del score_arr\n",
    "    del date_year_arr\n",
    "    del date_month_arr\n",
    "    del gmw_ext_msk\n",
    "    # Increment the tile number for user feedback.\n",
    "    n_tile += 1\n",
    "    # Restart the dask workers to ensure all the memory etc. is cleared.\n",
    "    '''\n",
    "    if n_tile % 10 == 0:\n",
    "        client.restart(wait_for_workers=False)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce514953-243e-4d2e-94a5-78793024ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the dask cluster\n",
    "cluster.shutdown()\n",
    "#client.close()\n",
    "#cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473af7e4-5bfb-4ab7-a297-d22d30d1e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if os.path.exists(tmp_path):\n",
    "#    shutil.rmtree(tmp_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
