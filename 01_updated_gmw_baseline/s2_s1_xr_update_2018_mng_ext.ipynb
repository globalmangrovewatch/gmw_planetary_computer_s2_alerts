{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e1ff9d-b008-4d18-a7b9-c0d80005851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_gateway import GatewayCluster\n",
    "import dask.distributed\n",
    "import dask.utils\n",
    "import dask.array\n",
    "import dask\n",
    "import planetary_computer\n",
    "from pystac_client import Client\n",
    "import odc.stac\n",
    "import numpy\n",
    "import xarray\n",
    "import rasterio\n",
    "import rasterio.enums\n",
    "import gc\n",
    "import math\n",
    "import os\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b35566f-fa34-428c-badb-d4501b7f4890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sen2_vld_msk(scns_xa, bands, qa_pxl_msk=\"SCL\", out_no_data_val=0):\n",
    "    scns_lcl_xa = scns_xa.copy()\n",
    "    for band in bands:\n",
    "        scns_lcl_xa[band].values[scns_lcl_xa[\"SCL\"].values == 0] = out_no_data_val  # No Data\n",
    "        scns_lcl_xa[band].values[scns_lcl_xa[\"SCL\"].values == 1] = out_no_data_val  # Saturation\n",
    "        scns_lcl_xa[band].values[scns_lcl_xa[\"SCL\"].values == 2] = out_no_data_val  # Cast Shadow\n",
    "        scns_lcl_xa[band].values[scns_lcl_xa[\"SCL\"].values == 3] = out_no_data_val  # Cloud Shadows\n",
    "        scns_lcl_xa[band].values[scns_lcl_xa[\"SCL\"].values == 8] = out_no_data_val  # Cloud Medium Probability\n",
    "        scns_lcl_xa[band].values[scns_lcl_xa[\"SCL\"].values == 9] = out_no_data_val  # Cloud High Probability\n",
    "        scns_lcl_xa[band].values[scns_lcl_xa[\"SCL\"].values == 10] = out_no_data_val # Thin Cirrus\n",
    "    return scns_lcl_xa\n",
    "\n",
    "def get_img_metadata(img_file):\n",
    "    img_data_obj = rasterio.open(img_file)\n",
    "    img_bounds = img_data_obj.bounds\n",
    "    img_bbox = [img_bounds.left, img_bounds.bottom, img_bounds.right, img_bounds.top]\n",
    "    img_x_res, img_y_res  = img_data_obj.res\n",
    "    if img_y_res > 0:\n",
    "        img_y_res = img_y_res * (-1)\n",
    "    img_data_obj = None\n",
    "    return img_bbox, img_x_res, img_y_res\n",
    "\n",
    "def get_img_band_array(img_file, band=1):\n",
    "    img_data_obj = rasterio.open(img_file)\n",
    "    img_arr = img_data_obj.read(band)\n",
    "    img_data_obj = None\n",
    "    return img_arr\n",
    "\n",
    "def test_asset_urls(signed_items):\n",
    "    chkd_items = list()\n",
    "    for scn_item in signed_items:\n",
    "        assets_present = True\n",
    "        for asset_name in scn_item.assets:\n",
    "            try:\n",
    "                if (\n",
    "                    urllib.request.urlopen(scn_item.assets[asset_name].href).getcode()\n",
    "                    != 200\n",
    "                ):\n",
    "                    assets_present = False\n",
    "                    break\n",
    "            except urllib.error.HTTPError:\n",
    "                assets_present = False\n",
    "                break\n",
    "            time.sleep(0.1)\n",
    "        if assets_present:\n",
    "            chkd_items.append(scn_item)\n",
    "    print(f\"Before: {len(signed_items)}\")\n",
    "    print(f\"After: {len(chkd_items)}\")\n",
    "    return chkd_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c90e00-145b-41ef-82dc-7173d40d861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = GatewayCluster()  # Creates the Dask Scheduler. Might take a minute.\n",
    "cluster.adapt(minimum=4, maximum=24)\n",
    "print(cluster.dashboard_link)\n",
    "\n",
    "client = dask.distributed.Client(cluster, timeout=10)\n",
    "odc.stac.configure_rio(cloud_defaults=True, client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeb5c79-24dd-4564-aa86-d0289cf141c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef2266b-a38e-4d1c-97d1-53a5131293b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date range of the ROI\n",
    "time_range = \"2018-01-01/2018-12-31\"\n",
    "date_str = \"201812\"\n",
    "# Bands to be read\n",
    "bands = [\"B03\", \"B04\", \"B08\", \"B11\", \"SCL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280ad86-c788-4ff4-a035-346400e467f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 5x5 circular operator\n",
    "morph_op3 = ndimage.generate_binary_structure(2, 1)\n",
    "morph_op5 = numpy.zeros((5,5))\n",
    "morph_op5[2,2] = 1\n",
    "morph_op5 = ndimage.binary_dilation(morph_op5, structure=morph_op3, iterations=2).astype(morph_op5.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde66fe6-deed-450a-a0ce-533b73cac650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tiles to be processed.\n",
    "tiles_gdf = geopandas.read_file(\"../00_base_data/alert_region_tiles.geojson\")\n",
    "tiles = tiles_gdf[\"tile\"].values\n",
    "#tiles = tiles[1000:1100]\n",
    "\n",
    "tiles = tiles.tolist()\n",
    "#tiles.remove(\"N27W077\")\n",
    "\n",
    "n_tiles = len(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e9f39f-635e-4d45-967c-43ff37df325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_s1_data = False\n",
    "check_s2_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12897f4-86b0-4ef0-938a-15855fe4080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_img_dir = \"../gmw_2018_ext_tiles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d1a0d-b985-47f7-a972-2f0542e3ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img_dir = \"../gmw_2018_revised_ext_opt_s1\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a9f2a3-458b-48a9-b999-ce1c41ca023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tile = 0\n",
    "# Iterate through the tiles.\n",
    "for tile in tiles:\n",
    "    print(f\"{tile}: ({n_tile+1} of {n_tiles})\")\n",
    "    out_img_file = os.path.join(out_img_dir, f'gmw_{tile}_2018_alerts_ext.tif')\n",
    "    # Do not process tile if output file already exists.\n",
    "    if not os.path.exists(out_img_file):\n",
    "        # Define the GMW extent image file\n",
    "        gmw_tile_img = os.path.join(in_img_dir, f\"gmw_{tile}_2018_mng_ext.tif\")\n",
    "        # Get the bbox and image resolution of the input image.\n",
    "        bbox, img_x_res, img_y_res = get_img_metadata(gmw_tile_img)\n",
    "        \n",
    "        # Search for scenes.\n",
    "        search = catalog.search(collections=[\"sentinel-2-l2a\"], bbox=bbox, datetime=time_range, query={\"eo:cloud_cover\": {\"lt\": 50}})\n",
    "        items = search.get_all_items()\n",
    "        n_items = len(items)\n",
    "        print(f\"\\tN Sen2 Scenes: {n_items}\")\n",
    "        \n",
    "        ####################################################################\n",
    "        # Find the scenes for the period of interest.\n",
    "        s1_search = catalog.search(collections=[\"sentinel-1-rtc\"], bbox=bbox, datetime=time_range, query={\"sar:polarizations\": {\"eq\": [\"VV\", \"VH\"]}})\n",
    "        s1_items = s1_search.get_all_items()\n",
    "        n_s1_items = len(s1_items)\n",
    "        print(f\"\\tN Sen1 Items = {n_s1_items}\")\n",
    "        s1_avail = True\n",
    "        if n_s1_items < 1:\n",
    "            s1_avail = False\n",
    "        ####################################################################\n",
    "        \n",
    "        # Only continue analysis if there are scenes available.\n",
    "        if n_items > 0:\n",
    "            # Read the GMW extent into a numpy array\n",
    "            gmw_ext_msk = get_img_band_array(gmw_tile_img)\n",
    "            \n",
    "            # Sign all the items\n",
    "            signed_items = [planetary_computer.sign(item) for item in items]\n",
    "            if check_s2_data:\n",
    "                signed_items = test_asset_urls(signed_items)\n",
    "\n",
    "            # Read the data into dask xarray structure\n",
    "            sen2_scn_xa = odc.stac.stac_load(\n",
    "                signed_items,\n",
    "                bands=bands,\n",
    "                groupby=\"solar_day\",\n",
    "                #dtype=numpy.uint16,\n",
    "                chunks={\"time\":24, \"latitude\": 1024, \"longitude\": 1024},\n",
    "                bbox=bbox,\n",
    "                crs=\"EPSG:4326\",\n",
    "                resolution=img_x_res\n",
    "            )\n",
    "            \n",
    "            if s1_avail:\n",
    "                # Read the scenes into dask array structure and make persistant in memory\n",
    "                signed_s1_items = [planetary_computer.sign(item) for item in s1_items]\n",
    "                if check_s1_data:\n",
    "                    signed_s1_items = test_asset_urls(signed_s1_items)\n",
    "\n",
    "                sen1_scns_xa = odc.stac.stac_load(\n",
    "                    signed_s1_items,\n",
    "                    bands=[\"vh\"],\n",
    "                    groupby=\"solar_day\",\n",
    "                    chunks={\"time\":12, \"latitude\": 1024, \"longitude\": 1024},\n",
    "                    bbox=bbox,\n",
    "                    crs=\"EPSG:4326\",\n",
    "                    resolution=img_x_res\n",
    "                )\n",
    "                sen1_scns_dB_xa = 10 * numpy.log10(sen1_scns_xa)\n",
    "                sen1_scns_dB_xa[\"vh\"] = sen1_scns_dB_xa.vh.where(sen1_scns_dB_xa.vh>-30)\n",
    "                sen1_scns_dB_min_xa = sen1_scns_dB_xa.min(dim='time', skipna=True).compute()\n",
    "\n",
    "            # Store the dataset input dask cluster memory\n",
    "            # Comment out for larger datasets which don't fit into memory.\n",
    "            sen2_scn_xa = sen2_scn_xa.persist()\n",
    "\n",
    "            # Apply cloud masks etc.\n",
    "            sen2_scn_xa = sen2_scn_xa.map_blocks(apply_sen2_vld_msk, kwargs={\"bands\":bands})\n",
    "\n",
    "            # 'Clean' up the bands to remove any values less than zero - shouldn't be needed but just incase...\n",
    "            sen2_scn_xa['B03'] = sen2_scn_xa.B03.where(sen2_scn_xa.B03>0)\n",
    "            sen2_scn_xa['B04'] = sen2_scn_xa.B04.where(sen2_scn_xa.B04>0)\n",
    "            sen2_scn_xa['B08'] = sen2_scn_xa.B08.where(sen2_scn_xa.B08>0)\n",
    "            sen2_scn_xa['B11'] = sen2_scn_xa.B11.where(sen2_scn_xa.B11>0)\n",
    "\n",
    "            # Calculate the NDWI (two versions)\n",
    "            ndwi1_scn_xa = ((sen2_scn_xa.B03-sen2_scn_xa.B08)/(sen2_scn_xa.B03+sen2_scn_xa.B08))\n",
    "            ndwi2_scn_xa = ((sen2_scn_xa.B03-sen2_scn_xa.B11)/(sen2_scn_xa.B03+sen2_scn_xa.B11))\n",
    "            \n",
    "            # Calculate the NDVI\n",
    "            ndvi_scn_xa = ((sen2_scn_xa.B08-sen2_scn_xa.B04)/(sen2_scn_xa.B08+sen2_scn_xa.B04))\n",
    "            \n",
    "            # Calculate the MVI\n",
    "            mvi_scn_xa = (sen2_scn_xa.B08-sen2_scn_xa.B03)/(sen2_scn_xa.B11+sen2_scn_xa.B03)\n",
    "\n",
    "            # Apply threshold\n",
    "            water1_pxls_xa = ndwi1_scn_xa > -0.1\n",
    "            water2_pxls_xa = ndwi2_scn_xa > 0.15\n",
    "            veg_pxls_xa = ndvi_scn_xa < 0.1\n",
    "            mng_pxls_xa = mvi_scn_xa < 0.1\n",
    "\n",
    "            # Summarise the changes by summing through time.\n",
    "            water1_pxls_count_xa = water1_pxls_xa.sum(dim=\"time\", skipna=True)\n",
    "            water2_pxls_count_xa = water2_pxls_xa.sum(dim=\"time\", skipna=True)\n",
    "            veg_pxls_count_xa = veg_pxls_xa.sum(dim=\"time\", skipna=True)\n",
    "            mng_pxls_count_xa = mng_pxls_xa.sum(dim=\"time\", skipna=True)\n",
    "            \n",
    "            dask.compute(water1_pxls_count_xa, water2_pxls_count_xa, veg_pxls_count_xa, mng_pxls_count_xa)\n",
    "            \n",
    "            # Update the GMW extent.\n",
    "            gmw_ext_msk[water1_pxls_count_xa.values > 4] = 0\n",
    "            gmw_ext_msk[water2_pxls_count_xa.values > 4] = 0\n",
    "            gmw_ext_msk[veg_pxls_count_xa.values > 4] = 0\n",
    "            gmw_ext_msk[mng_pxls_count_xa.values > 4] = 0\n",
    "            if s1_avail:\n",
    "                gmw_ext_msk[sen1_scns_dB_min_xa[\"vh\"].values < -19] = 0\n",
    "            \n",
    "            # Apply erosion to resulting mask.\n",
    "            gmw_ext_msk_erode = ndimage.binary_erosion(gmw_ext_msk, structure=morph_op5)\n",
    "\n",
    "            # Get the image shape (i.e., number of pixels)\n",
    "            img_shp = gmw_ext_msk.shape\n",
    "            \n",
    "            # Define the output image spatial transformation.\n",
    "            out_img_transform = rasterio.transform.Affine(img_x_res, 0.0, bbox[0], 0.0, img_y_res, bbox[3])\n",
    "           \n",
    "            with rasterio.open(out_img_file,\n",
    "                                'w',\n",
    "                                driver='COG',\n",
    "                                height=img_shp[0],\n",
    "                                width=img_shp[1],\n",
    "                                count=2,\n",
    "                                dtype=numpy.uint8,\n",
    "                                crs='epsg:4326',\n",
    "                                transform=out_img_transform,\n",
    "                            ) as out_img_dataset:\n",
    "            \n",
    "                # Write output array to the image file\n",
    "                out_img_dataset.write(gmw_ext_msk, 1)\n",
    "                out_img_dataset.set_band_description(1, \"MngExt2018\")\n",
    "                \n",
    "                out_img_dataset.write(gmw_ext_msk_erode, 2)\n",
    "                out_img_dataset.set_band_description(2, \"MngExt2018Erode\")\n",
    "\n",
    "\n",
    "            # Delete the data arrays to as not used any more.\n",
    "            del sen2_scn_xa\n",
    "            del ndwi1_scn_xa\n",
    "            del ndwi2_scn_xa\n",
    "            del ndvi_scn_xa\n",
    "            del mvi_scn_xa\n",
    "            del water1_pxls_count_xa\n",
    "            del water2_pxls_count_xa\n",
    "            del veg_pxls_count_xa\n",
    "            del mng_pxls_count_xa\n",
    "            del gmw_ext_msk\n",
    "            del gmw_ext_msk_erode\n",
    "            if s1_avail:\n",
    "                del sen1_scns_xa\n",
    "                del sen1_scns_dB_xa\n",
    "                del sen1_scns_dB_min_xa\n",
    "            # Restart the dask workers to ensure all the memory etc. is cleared.\n",
    "            #client.restart(wait_for_workers=False)\n",
    "    # Increment the tile number for user feedback.\n",
    "    n_tile += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eff0f7c-7dd7-43e5-b617-5eac63077ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the dask cluster\n",
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7895f85a-122a-4535-ab7d-40b2ad9eff5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
